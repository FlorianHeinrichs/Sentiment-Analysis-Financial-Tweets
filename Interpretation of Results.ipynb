{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Sentiment Analysis - Interpretation of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make imports and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from joblib import load\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "model = load('final_model.joblib')\n",
    "vectorizer = spacy.load('en_core_web_lg')\n",
    "mean_vec = load('mean_vec.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran, the company has no plans to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                           sentence  label\n",
       "0   neutral  According to Gran, the company has no plans to...      0\n",
       "1   neutral  Technopolis plans to develop in stages an area...      0\n",
       "2  negative  The international electronic industry company ...     -1\n",
       "3  positive  With the new production plant the company woul...      1\n",
       "4  positive  According to the company 's updated strategy f...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/all-data-v2.csv', sep=';', encoding='latin-1')\n",
    "\n",
    "def remove_quot_mark(string):\n",
    "    if string[0] == ' ':\n",
    "        string = string[1:]\n",
    "    if string[0] == '\"':\n",
    "        string = string[1:]\n",
    "    if string[-1] =='\"':\n",
    "        string = string[:-1]\n",
    "    return string\n",
    "        \n",
    "data['sentence'] = data['sentence'].apply(remove_quot_mark)\n",
    "data['label'] = data.apply(lambda row: int(row['sentiment']=='positive') - int(row['sentiment']=='negative'), axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to transform data into Word2Vec representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_w2v_test(X_test, vectorizer, mean_vec):\n",
    "    \n",
    "    with vectorizer.disable_pipes():\n",
    "        test_vectors = np.array([vectorizer(text).vector for text in X_test])\n",
    "\n",
    "    X_test = test_vectors - mean_vec\n",
    "    return X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate \"out-of-sample\" performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1241  105   17]\n",
      " [1663 1178   38]\n",
      " [ 472   35   97]]\n",
      "\n",
      "\n",
      "Estimated precision:0.5191910854312836\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(transform_w2v_test(data['sentence'], vectorizer, mean_vec))\n",
    "cm = confusion_matrix(data['label'],y_pred, labels=[1,0,-1])\n",
    "precision = np.trace(cm)/np.sum(cm)\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "print(cm)\n",
    "print('\\n\\nEstimated precision:' + str(precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"out-of-sample\" precision is rather poor as only approx. 50% of the data is classified correctly. There are more than 60% neutral data, so classifying all data as neutral would yield a better precision. The neutral data could be considered as noise. The following results investigate the perfomance of the procedure with only positive and negative data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model trained with positive and negative data only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1271   92]\n",
      " [ 447  157]]\n",
      "\n",
      "\n",
      "Estimated precision:0.7259786476868327\n"
     ]
    }
   ],
   "source": [
    "model = load('final_model_pos_neg.joblib')\n",
    "vectorizer = load('vectorizer_pos_neg.joblib')\n",
    "\n",
    "data2 = data[data['sentiment'] != 'neutral']\n",
    "\n",
    "y_pred = model.predict(vectorizer.transform(data2['sentence']))\n",
    "cm = confusion_matrix(data2['label'],y_pred, labels=[1,-1])\n",
    "precision = np.trace(cm)/np.sum(cm)\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "print(cm)\n",
    "print('\\n\\nEstimated precision:' + str(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive sentences: 1363\n",
      "Number of negative sentences: 604\n"
     ]
    }
   ],
   "source": [
    "val_counts = data2['label'].value_counts()\n",
    "\n",
    "print('Number of positive sentences: ' + str(val_counts[1]) + '\\n' \n",
    "      + 'Number of negative sentences: ' + str(val_counts[-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
